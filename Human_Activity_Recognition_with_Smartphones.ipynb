{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Hle1ZAamL99C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57cac8e9-65d7-4b9b-aba6-5553ec357d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Załadowane CSV: ['./train.csv', './test.csv']\n",
            "Połączone shape: (10299, 563)\n",
            "Kolumny przykładowe: ['tBodyAcc-mean()-X', 'tBodyAcc-mean()-Y', 'tBodyAcc-mean()-Z', 'tBodyAcc-std()-X', 'tBodyAcc-std()-Y', 'tBodyAcc-std()-Z', 'tBodyAcc-mad()-X', 'tBodyAcc-mad()-Y', 'tBodyAcc-mad()-Z', 'tBodyAcc-max()-X', 'tBodyAcc-max()-Y', 'tBodyAcc-max()-Z', 'tBodyAcc-min()-X', 'tBodyAcc-min()-Y', 'tBodyAcc-min()-Z', 'tBodyAcc-sma()', 'tBodyAcc-energy()-X', 'tBodyAcc-energy()-Y', 'tBodyAcc-energy()-Z', 'tBodyAcc-iqr()-X', 'tBodyAcc-iqr()-Y', 'tBodyAcc-iqr()-Z', 'tBodyAcc-entropy()-X', 'tBodyAcc-entropy()-Y', 'tBodyAcc-entropy()-Z', 'tBodyAcc-arCoeff()-X,1', 'tBodyAcc-arCoeff()-X,2', 'tBodyAcc-arCoeff()-X,3', 'tBodyAcc-arCoeff()-X,4', 'tBodyAcc-arCoeff()-Y,1']\n",
            "Detected mapping: {'ax': 'tBodyAcc-mean()-X', 'ay': 'tBodyAcc-mean()-Y', 'az': 'tBodyAcc-mean()-Z', 'gx': 'tBodyGyro-mean()-X', 'gy': 'tBodyGyro-mean()-Y', 'gz': 'tBodyGyro-mean()-Z'}\n",
            "Utworzono okien: 159\n",
            "Labels sample: {'LAYING': 55, 'STANDING': 49, 'WALKING': 32, 'SITTING': 18, 'WALKING_UPSTAIRS': 5}\n",
            "Feature matrix: (159, 60) n_classes: 5\n",
            "PCA explained cum: [0.17546337 0.2906061  0.36808644 0.4425775  0.50205276 0.55167704\n",
            " 0.59620875 0.6383804  0.67591147 0.70712805]\n",
            "Classes: ['LAYING' 'SITTING' 'STANDING' 'WALKING' 'WALKING_UPSTAIRS']\n",
            "RF CV acc: 0.284 ± 0.107\n",
            "XGB CV acc: 0.292 ± 0.063\n",
            "RF test acc: 0.40625 XGB test acc: 0.375\n",
            "Saved RF/XGB models and preprocessors to disk. Wygenerowane wykresy w ./figures\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Pipeline + dodatkowe wykresy + XGBoost\n",
        "import os, glob, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import signal\n",
        "from scipy.fft import rfft, rfftfreq\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# OPTIONAL: xgboost (pip install xgboost)\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"Brakuje xgboost. Zainstaluj: pip install xgboost\") from e\n",
        "\n",
        "# ========== USTAWIENIA ==========\n",
        "SAMPLE_RATE = 50\n",
        "WINDOW_SEC = 2.56\n",
        "STEP_SEC = WINDOW_SEC / 2\n",
        "WINDOW_SAMPLES = int(WINDOW_SEC * SAMPLE_RATE)\n",
        "\n",
        "OUTPUT_FIGURES = './figures'\n",
        "os.makedirs(OUTPUT_FIGURES, exist_ok=True)\n",
        "\n",
        "# Wywołaj load_and_segment_auto('.') aby otrzymać segments, labels, meta\n",
        "segments, labels, meta = load_and_segment_auto('.')  # użyj istniejącej funkcji\n",
        "print(\"Labels sample:\", pd.Series(labels).value_counts().to_dict())\n",
        "\n",
        "# ========== Preprocessing (filtrowanie) ==========\n",
        "for seg in segments:\n",
        "    for c in ['ax','ay','az','gx','gy','gz']:\n",
        "        if c in seg.columns:\n",
        "            try:\n",
        "                seg[c + '_filt'] = apply_filter(seg[c].values)\n",
        "                seg[c + '_filt'] = signal.detrend(seg[c + '_filt'])\n",
        "            except Exception:\n",
        "                seg[c + '_filt'] = seg[c].values\n",
        "\n",
        "# ========== Feature extraction ==========\n",
        "feature_rows = []\n",
        "labels_clean = []\n",
        "for seg, lab in zip(segments, labels):\n",
        "    f = extract_features_from_segment(seg)\n",
        "    feature_rows.append(f)\n",
        "    labels_clean.append(lab if lab is not None else 'UNKNOWN')\n",
        "\n",
        "X_df = pd.DataFrame(feature_rows).fillna(0)\n",
        "y = np.array(labels_clean)\n",
        "print(\"Feature matrix:\", X_df.shape, \"n_classes:\", len(np.unique(y)))\n",
        "\n",
        "# ========== Visualization 1: rozkład klas ==========\n",
        "plt.figure(figsize=(8,4))\n",
        "vc = pd.Series(y).value_counts().sort_values(ascending=False)\n",
        "plt.bar(vc.index.astype(str), vc.values)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.ylabel('Liczba okien')\n",
        "plt.title('Rozkład etykiet (okna)')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_FIGURES, 'class_distribution.png'), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# ========== VarianceThreshold + Skalowanie + PCA (do wizualizacji) ==========\n",
        "vt = VarianceThreshold(threshold=1e-4)\n",
        "X_var = vt.fit_transform(X_df)  # użyjemy X_var do trenowania modeli (łatwiej interpretować importances)\n",
        "feature_mask = vt.get_support()\n",
        "feature_names_kept = X_df.columns[feature_mask].tolist()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_var)\n",
        "\n",
        "pca = PCA(n_components=min(10, X_scaled.shape[1]))\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "print(\"PCA explained cum:\", pca.explained_variance_ratio_.cumsum())\n",
        "\n",
        "# ========== Visualization 2: PCA scatter 2 pierwsze składowe ==========\n",
        "le_vis = LabelEncoder()\n",
        "y_enc_vis = le_vis.fit_transform(y)\n",
        "plt.figure(figsize=(6,5))\n",
        "for lbl in np.unique(y_enc_vis):\n",
        "    idx = y_enc_vis == lbl\n",
        "    plt.scatter(X_pca[idx,0], X_pca[idx,1], s=8, alpha=0.6, label=str(le_vis.inverse_transform([lbl])[0]))\n",
        "plt.xlabel('PC1'); plt.ylabel('PC2'); plt.title('PCA 1 vs 2')\n",
        "plt.legend(bbox_to_anchor=(1.05,1), loc='upper left', fontsize='small')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_FIGURES,'pca_scatter.png'), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# ========== Przygotowanie etykiet do modelu ==========\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "classes = le.classes_\n",
        "print(\"Classes:\", classes)\n",
        "\n",
        "# Podzielmy dane na train/test (dla wykresów/oceny finalnej)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_var, y_enc, test_size=0.2, stratify=y_enc, random_state=42)\n",
        "\n",
        "# ========== Trening: RandomForest i XGBoost (multi-class) ==========\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "xgb = XGBClassifier(n_estimators=200, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "\n",
        "# Cross-val (5-fold) porównanie accuracy\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rf_scores = cross_val_score(rf, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "xgb_scores = cross_val_score(xgb, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "print(\"RF CV acc: %.3f ± %.3f\" % (rf_scores.mean(), rf_scores.std()))\n",
        "print(\"XGB CV acc: %.3f ± %.3f\" % (xgb_scores.mean(), xgb_scores.std()))\n",
        "\n",
        "# Dopasuj finalne modele na całym X_train\n",
        "rf.fit(X_train, y_train)\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Ewaluacja na X_test\n",
        "rf_preds = rf.predict(X_test)\n",
        "xgb_preds = xgb.predict(X_test)\n",
        "rf_acc = accuracy_score(y_test, rf_preds)\n",
        "xgb_acc = accuracy_score(y_test, xgb_preds)\n",
        "print(\"RF test acc:\", rf_acc, \"XGB test acc:\", xgb_acc)\n",
        "\n",
        "# ========== Visualization 3: feature importances (top 20) ==========\n",
        "importances_rf = rf.feature_importances_\n",
        "importances_xgb = xgb.feature_importances_\n",
        "idx_rf = np.argsort(importances_rf)[::-1][:20]\n",
        "idx_xgb = np.argsort(importances_xgb)[::-1][:20]\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "names = [feature_names_kept[i] for i in idx_rf]\n",
        "vals = importances_rf[idx_rf]\n",
        "plt.barh(range(len(names))[::-1], vals, align='center')\n",
        "plt.yticks(range(len(names))[::-1], names)\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Top 20 feature importances (RandomForest)')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_FIGURES, 'feature_importances_rf.png'), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "names = [feature_names_kept[i] for i in idx_xgb]\n",
        "vals = importances_xgb[idx_xgb]\n",
        "plt.barh(range(len(names))[::-1], vals, align='center')\n",
        "plt.yticks(range(len(names))[::-1], names)\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Top 20 feature importances (XGBoost)')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_FIGURES, 'feature_importances_xgb.png'), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# ========== Visualization 4: confusion matrix (XGB) ==========\n",
        "cm = confusion_matrix(y_test, xgb_preds)\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45, ha='right')\n",
        "plt.yticks(tick_marks, classes)\n",
        "plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
        "plt.title('Confusion matrix (XGBoost) on test set')\n",
        "# annotate counts\n",
        "thresh = cm.max() / 2\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_FIGURES, 'confusion_matrix_xgb.png'), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# ========== Dodatkowe: porównanie ROC dla binary (jeśli masz 2 klasy) ==========\n",
        "if len(classes) == 2:\n",
        "    # train a binary xgb/rf on X_train and plot ROC (one-vs-rest not needed)\n",
        "    from sklearn.metrics import roc_curve, auc\n",
        "    rf_prob = rf.predict_proba(X_test)[:,1]\n",
        "    xgb_prob = xgb.predict_proba(X_test)[:,1]\n",
        "    fpr, tpr, _ = roc_curve(y_test, rf_prob)\n",
        "    fpr2, tpr2, _ = roc_curve(y_test, xgb_prob)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.plot(fpr, tpr, label=f'RF AUC={auc(fpr,tpr):.2f}')\n",
        "    plt.plot(fpr2, tpr2, label=f'XGB AUC={auc(fpr2,tpr2):.2f}')\n",
        "    plt.plot([0,1],[0,1],'--', color='gray')\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.legend(); plt.title('ROC (test)')\n",
        "    plt.tight_layout(); plt.savefig(os.path.join(OUTPUT_FIGURES,'roc_compare.png'), dpi=150); plt.close()\n",
        "\n",
        "# ========== Zapis modeli i obiektów ==========\n",
        "joblib.dump(rf, 'rf_model.joblib')\n",
        "joblib.dump(xgb, 'xgb_model.joblib')\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "joblib.dump(vt, 'variance_threshold.joblib')\n",
        "joblib.dump(pca, 'pca.joblib')\n",
        "joblib.dump(le, 'label_encoder.joblib')\n",
        "print(\"Saved RF/XGB models and preprocessors to disk. Wygenerowane wykresy w\", OUTPUT_FIGURES)\n"
      ]
    }
  ]
}